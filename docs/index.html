
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Final Project Proposal</title>  
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>
 
<body>
<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2022</h1>
<h1 align="middle">Final Project</h1>
<h2 align="middle">Shilpa Sathyanathan, David McAllister, James Dai, Ethan Gnibus</h2>
<h4 align="middle"> Project Link: https://github.com/shilpasath/cs184-finalproj</h4>

<div>

<h2 align="middle">Abstract</h2>
	<p>Cal Rally Com is interested in creating an interactive experience for people who attend football games to play with while theyâ€™re bored during the game, timeouts, or halftime. We think that being able to orient meshes based on an attendee's position in the football stands would be useful and all them to watch recaps. If we can orient a mesh correctly from every point in the stadium, then we can properly do things like orient the paths that players have moved during the game, the plays that each team was running, etc. 
	</p><p> The goal of this project is to make live events more entertaining. Some hard parts of this project are figuring out where the user is in the stadium, extracting features from the stadium (corners, end goal lines, etc), and displaying the features in the correct place when you point your phone at the field.</p>

<h3 align="middle">Goals and Deliverables</h3>

<h4> What We Plan to Deliver</h4>
    <p> We plan to use frame rates and error metrics. For quality, we will determine which and how many effects can be run on mobile hardware. </p>
	
<h4> What We Hope to Deliver</h4>	
    <p> We hope to be able to do this segmentation on every frame or maybe for every other frame. We hope to be able to see how much that would impact our accuracy as well.</p>


<h3 align="middle">Schedule</h3>
<ul>
  <li>Go to Memorial Stadium and write software for detecting where we are on the field
    <ul>
      <li>Get an app running with ARKit</li>
      <li>Make a game loop to extract a real world point and draw it to the screen with ARKit.</li>
      <li>Extract four real world points, interpolate between them, and draw a plane with their barycentric coordinates to the screen.</li>
      <li>Apply this to the stadium. </li>
         <ul> 
           <li>Try to extract user position in the stadium </li>
           <li>Use markers on the field to extract relative positioning</li>
           <li> Draw the barycentric coordinates to the field.</li>
           <li> Flex goal: draw a mesh on the field!</li>
         </ul>
    </ul>  
  </li>
  <li> Debugging and Testing</li> 
   <ul>
     <li> Perfect code to ensure the relative positioning extracted and plane fit nicely into the stadium. Constantly iterate until working well.</li>
   </ul>
  <li>Create a cool demo: plane on the football field, colored using barycentric coordinates. Potentially more if time permits (i.e. big Cal bear).</li> 
   <ul>
     <li>Segment field by yard lines for more effects</li>
     <li>Cross-device timing for shared animations, visual effects </li>
   </ul>
</ul>
	
<h3 align="middle">Resources</h3>
<ol>
  <li>We will be using ARKit (Swift and XCode) and foresee ourselves using ARKit-related documentation and online resources. </li>
  <li>We'll also be using iPhone and iPad hardware. </li>
</ol>

</body>
</html>
